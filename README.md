# Motion App â€“ Real-Time Emotion Detection in Flutter Web

This Flutter web app uses a webcam to detect human facial expressions (like happy, sad, angry, etc.) in real time using `face-api.js` through JavaScript interop.

## ğŸ§  Features

- Real-time facial emotion detection via webcam
- Face detection using `TinyFaceDetector`
- Emotion classification using `FaceExpressionNet`
- Live integration with Flutter UI
- JavaScript interop with Dart
- Hosted on Netlify

## ğŸš€ Demo

ğŸ‘‰ **Live Preview**: [https://motion-ai-web.netlify.app/](https://motion-ai-web.netlify.app/)

## ğŸ“¸ How It Works

1. The app requests camera access from the user.
2. It uses `face-api.js` to detect a face and read facial expressions.
3. The dominant emotion (e.g., happy, angry, surprised) is extracted.
4. Detected emotion is passed to Flutter via JS interop and shown in the UI.

## ğŸ“ Project Structure

motion_app/

â”œâ”€â”€ web/

â”‚ â”œâ”€â”€ index.html

â”‚ â”œâ”€â”€ emotion.js

â”‚ â””â”€â”€ models/ # contains TinyFaceDetector and FaceExpressionNet weights

â”œâ”€â”€ lib/

â”‚ â””â”€â”€ main.dart

â”œâ”€â”€ pubspec.yaml

â”œâ”€â”€ README.md

â””â”€â”€ ...
